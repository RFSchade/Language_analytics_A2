# Language Analytics Assignment 2
## Assignment description
This repository contains my solution to assignment 2 for the Language Analytics course at Aarhus university. The goal of this assignment is to write a program that uses named entity recognition (NER) and sentiment analysis techniques in one of two different ways. I chose to run sentiment analysis on and identify NERs in a dataset of fake and real news.    

## Methods
The script loads the dataset, divides it into subsets of FAKE and REAL news, and runs sentiment analysis on the data using the [VADER](https://pypi.org/project/vaderSentiment/) (full citation at the end of the README file) and [spacyTextBlob](https://pypi.org/project/spacytextblob/) python modules, while using the [spacy](https://pypi.org/project/spacy/) module to identify geopolitical entities (GPEs) in the headlines. It then plots the 20 most frequent GPEs with their associated the sentiment scores.     

## Repository structure
in: Folder for input data    
notebooks: Folder for experimental code    
output: Folder for the output generated by the script – at present it contains 10 files:    
- FAKE_blob_plot.png:
    - Generated by running sentiment.py – contains two figures plotting the two spacyTextBlob sentiment scores (polarity and subjectivity) of the 20 most frequent GPEs in the FAKE news subset.
- FAKE_blob_sentiment.csv:
    - Generated by running sentiment.py – a dataframe containing the sentiment scores for the FAKE news subset of the data calculated using spacyTextBlob. The “ID” column contains the id of the article of the analyzed headline, “polatiry” contains the polarity of the headline, “subjectivity” contains the subjectivity of the headline, and “GPE” contains a GPE found in the headline. Each row contains information pertaining to one GPE.
- FAKE_freq_plot.png:
    - Generated by running sentiment.py – contains a plot of the nr. of occurrences of the 20 most frequent GPEs in the FAKE news subset
- FAKE_vader_plot.png:
    - Generated by running sentiment.py – contains a plot of three VADER sentiment scores (negative, neutral, and positive scores) of the 20 most frequent GPEs in the FAKE news subset.
- FAKE_vader_sentiment.csv:
    - Generated by running sentiment.py – a dataframe containing the sentiment scores for the FAKE news subset of the data calculated using VADER. The “ID” column contains the id of the article of the analyzed headline, “neg” contains the negative score of the headline, “neu” contains the neutral score of the headline, “pos” contains the positive score of the headline, “compound” contains the compound score of the headline, and “GPE” contains a GPE found in the headline. Each row contains information pertaining to one GPE.

- REAL_blob_plot.png:
    - Generated by running sentiment.py – contains two figures plotting the two spacyTextBlob sentiment scores (polarity and subjectivity) of the 20 most frequent GPEs in the FAKE news subset.
- REAL_blob_sentiment.csv:
    - Generated by running sentiment.py – a dataframe containing the sentiment scores for the REAL news subset of the data calculated using spacyTextBlob. The “ID” column contains the id of the article of the analyzed headline, “polatiry” contains the polarity of the headline, “subjectivity” contains the subjectivity of the headline, and “GPE” contains a GPE found in the headline. Each row contains information pertaining to one GPE.
- REAL_freq_plot.png:
    - Generated by running sentiment.py – contains a plot of the nr. of occurrences of the 20 most frequent GPEs in the REAL news subset
- REAL_vader_plot.png:
    - Generated by running sentiment.py – contains a plot of three VADER sentiment scores (negative, neutral, and positive scores) of the 20 most frequent GPEs in the REAL news subset.
- REAL_vader_sentiment.csv:
    - Generated by running sentiment.py – a dataframe containing the sentiment scores for the FAKE news subset of the data calculated using VADER. The “ID” column contains the id of the article of the analyzed headline, “neg” contains the negative score of the headline, “neu” contains the neutral score of the headline, “pos” contains the positive score of the headline, “compound” contains the compound score of the headline, and “GPE” contains a GPE found in the headline. Each row contains information pertaining to one GPE.

src: Folder for python scripts        
-	\_\_init__.py
- sentiment.py

github_link.txt: link to github repository    
requirements.txt: txt file containing the modules required to run the code    

## Usage
Modules listed in requirements.txt should be installed before scripts are run.    
__Input data__    
The format of the input data should be a .csv file with the name “fake_or_real_news.csv”. Each row in the dataframe should represent a news article. It should have the following columns: “Unnamed 0” containing an id for the article, “label” containing a label deciding if the article in question is fake or real news (either “FAKE” or “REAL”) and “title” containing the headline of the article.    
__sentiment.py__    
To analyze the data, run sentiment.py from the Language_analytics_A2 repository folder. The script has no arguments.    
Example of code running the script from the terminal:    
```
python src/sentiment.py
```

## Discussion of results
Looking at the spacyTextBlob scores, both polarity and subjectivity tends to spike higher in the REAL news subset of the data, which seems to the assumption that fake news are more emotional and bias than real news. As spacyTextBlob includes a function that shows which parts of a text the score was based on, further analysis might be beneficial.     
Looking at the VADER scores, both news subsets tend to have a much higher neutral score than positive and negative, and the negative score is often higher than the positive.     

## Citations
-	Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.
